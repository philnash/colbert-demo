[
  "Session: Turn Your Idea into an AI Application in Minutes: Quick Start with AI Templates \nPresenters: Gabriela de Quieroz, Director of AI - Microsoft for Startups, Microsoft, Aishwarya Srinivasan, Senior AI Advisor, Microsoft\nDate: 2024-06-25\nStart Time: 1300\nAbout: Building and deploying generative AI solutions can be challenging and time-consuming, especially for startups with limited resources and expertise. In this workshop, you will learn how to use AI templates and GitHub to quickly prototype and deploy generative AI applications in minutes. AI templates are ready-made solutions that leverage Microsoft Azure Services and GitHub features like GitHub Codespaces and GitHub Actions. You can access AI templates from the Microsoft for Startups Founders Hub, a platform that provides startups with exclusive access to tools, resources, and benefits to help them grow and scale their businesses. By the end of this workshop, you will be able to: \n • Understand the basics of generative AI and its applications for startups \n • Explore the AI templates available on the Microsoft for Startups Founders Hub \n • Select an AI template that matches your idea and customize it to your needs \n • Deploy your generative AI application to a web app or a chatbot\n • Test and iterate on your generative AI application and get feedback from users Prerequisites: \n • A GitHub account \n • A Microsoft Azure account (you can get a free trial or a credit through the Microsoft for Startups program) \n • An Azure subscription with access enabled for the Azure OpenAI Service \n • A basic understanding of generative AI and GitHub (optional)",
  "Session: Build, Evaluate and Deploy a RAG-based retail copilot with Azure AI\nPresenters: Cedric Vidal, Principal AI Advocate, Microsoft, David Smith, Principal Cloud Advocate, Microsoft\nDate: 2024-06-25\nStart Time: 1530\nAbout: Building generative AI applications for production requires a paradigm shift to LLM Ops, with new tools, platforms and processes for orchestrating end-to-end development workflows. In this session, you’ll learn to build, evaluate and deploy an enterprise copilot application end-to-end, using a code-first approach with Azure AI Studio and Prompt flow. From ideating your scenario with your data, to evaluating it for quality locally and on Azure, then deploying it for real-world usage.",
  "Session: Building with Generative AI on AWS: A Hands-On Starter\nPresenters: Banjo Obayomi, Senior Developer Advocate, AWS\nDate: 2024-06-25\nStart Time: 1300\nAbout: \"Learn to build generative AI applications on AWS using PartyRock and Amazon Bedrock. You will gain skills in prompt engineering and using the Bedrock API. We will also explore how to 'chat with your documents' through knowledge bases, retrieval augmented generation (RAG), embeddings, and agents. We will also use Amazon Q Developer to assist in coding and debugging.\nYou will be provided an AWS account to go through this workshop. Some familiarity with writing Python code is helpful. \"",
  "Session: Git push, get an AI API.\nPresenters: Ryan Fox-Tyler , SVP of Products and Engineering, Hypermode\nDate: 2024-06-26\nStart Time: 1230\nAbout: In this workshop you’ll build a demo that augments an app with AI for classification, natural language search, summarization, and outlier detection. Then you’ll learn how to iteratively improve before and after shipping to prod. We’ll use Hypermode to move fast and reduce infra overhead. You’ll walk away with a greater intuition for when & how to integrate AI without refactoring. Also, we have swag.",
  "Session: Architecting and Testing Controllable Agents\nPresenters: Lance Martin, AI Engineer, LangChain\nDate: 2024-06-25\nStart Time: 900\nAbout: Evals & LLM Ops: LLM-powered autonomous agents combine (1) Tool calling, (2) Memory, and (3) Planning to autonomously perform tasks. While they hold tremendous promise, agent reliability has been a barrier for large-scale deployment and productionisation. We’ll cover ways to design and build reliable agents using LangGraph, which can support diverse self-corrective applications such as RAG and code generation. But, just as critically, we’ll cover ways to use LangSmith to test your agents, examining both agent's final response as well as agent tool use trajectories. Collectively, we’ll talk about three types of testing loops you can incorporate into your agent design process - at run time, pre-production, and for production monitoring.",
  "Session: Low Level Technicals of LLMs\nPresenters: Daniel Han, CEO, Unsloth\nDate: 2024-06-25\nStart Time: 900\nAbout: Open Models: This workshop will be split into 3x one hour blocks:\n1. How to analyze & fix LLMs - how to find and fix bugs in Gemma, Phi-3, Llama & tokenizers\n2. Finetuning with Unsloth - continued pretraining, reward modelling, QLoRA & more\n3. Deep dive into LLM technicals - hand deriving derivatives, SOTA finetuning tricks\n\nIt's recommended you have Python with Pytorch and Unsloth installed (or use online Google Colab / Kaggle). College level maths and programming would be helpful.",
  "Session: LLMs for the working programmer. Become a 10x programming centaur today!\nPresenters: Manuel Odendahl, Principal Engineer, The Tree Center\nDate: 2024-06-25\nStart Time: 900\nAbout: CodeGen & Dev Tools: In this hands-on workshop, learn how Large Language Models (LLMs) can significantly improve your productivity as a software developer. Drawing from three years of experience using LLMs in every aspect of his work as a principal engineer, the presenter will share practical insights and techniques that go beyond simple prompts and off-the-shelf tools.\n\nThrough a series of interactive exercises and real-world examples, participants will learn how to:\n\n1. Combine classic design patterns, such as domain-specific languages and declarative programming, with transformer-based models\n2. Identify the most effective ways to use LLMs for writing software, beyond simply having them generate code\n3. Create systems that use LLMs to write software that instructs LLMs to write more software\n\nThis workshop is designed for engineers and professionals working in software-related fields who want to use LLMs to solve concrete problems and improve their workflow. Attendees will gain valuable insights and practical techniques that they can immediately apply to their projects, regardless of their current level of expertise with LLMs.\n\nThe presenter, a passionate advocate for \"pragmatic programming\" with LLMs, has made over 6,000 GitHub contributions using these models in the past year, achieving a high level of quality that demonstrates the technology's potential.",
  "Session: Building & Scaling an AI Agent Swarm of low latency real time voice bots!\nPresenters: Damien Murphy, Senior Applied Engineer, Deepgram\nDate: 2024-06-25\nStart Time: 1045\nAbout: Multimodality: AI Agents are becoming more powerful at a rapid pace! In this talk you will learn best practices and considerations to think about when building your AI Agent Swarm. All aspects from low latency Speech to Text, Large Language Model RAG and Fine Tuning and Text to Speech. I will share open source code for how to build an AI Agent you can talk to with sub second latency end to end! You will learn how you can scale your AI Agents to handle 1000s or millions of concurrent conversations.",
  "Session: Systematically improving your RAG\nPresenters: Jason Liu, Consultant (Instructor), Independent, Ivan Leo, Research Engineer, 567 Labs (Instructor)\nDate: 2024-06-25\nStart Time: 1300\nAbout: RAG & LLM Frameworks: Evaluating and scaling Retrieval Augmented Generation (RAG) systems can be challenging due to the complexity and numerous components involved. This workshop aims to equip participants with a range of practical skills and techniques to systematically improve their RAG systems. We'll cover topics such as benchmarking retrieval systems, employing automated clustering to identify problematic queries or topics, and leveraging Open Telemetry to ensure that internal evaluation datasets accurately reflect real-world user queries. By mastering these techniques, participants will be able to make data-driven decisions that set their RAG applications apart from the competition.\n",
  "Session: GitHub Copilot - The World’s Most Widely Adopted AI Developer Tool\nPresenters: Dave Burnison, Senior Developer Advocate    , GitHub, Alex Malebranche ,  Global Engagement Lead, GitHub, Dimitrios Philliou, Product Manager, GitHub\nDate: 2024-06-25\nStart Time: 1300\nAbout: CodeGen & Dev Tools: GitHub Copilot was introduced as “Your AI pair programmer” in January of 2021. Since then, we have been adding more and more capabilities to increase developer productivity and happiness. We’ve gone from simply leveraging AI to generate code to explaining existing code, generating unit tests, propose fixes for bugs, making code robust / secure, summarizing pull requests, having conversations tailored to your organization’s repositories, providing answers to your questions based on your organization’s knowledge base and so much more! Let's explore how to get started with GitHub Copilot, its ever growing list of capabilities, and how to make the most out of the tool.",
  "Session: How to add secure code interpreting in your AI app\nPresenters: Vasek Mlejnsky, CEO, E2B\nDate: 2024-06-25\nStart Time: 1300\nAbout: In this workshop, I'll show you how to add secure AI code execution that supports any LLM in your AI app using E2B. AI-powered code execution improves reasoning of LLMs and allows you to build AI-based dashboards where users can chat with their data, generative UI, or coding agents like Devin.",
  "Session: From model weights to API endpoint with TensorRT-LLM\nPresenters: Philip Kiely, Head of Developer Relations, Baseten, Pankaj Gupta, Co-Founder, Baseten\nDate: 2024-06-25\nStart Time: 1300\nAbout: GPUs & Inference: TensorRT-LLM is the highest-performance model serving framework, but it can have a steep learning curve when you’re just getting started. We run TensorRT and TensorRT-LLM in production and have seen both the incredible performance gains it offers and the hurdles to overcome in getting it up and running. In this workshop, participants will learn how to start using TensorRT-LLM, including selecting a model to optimize, building an engine for it with TensorRT-LLM, setting batch sizes and sequence lengths, and running it on a cloud GPU.",
  "Session: The A to Z of Building AI Agents\nPresenters: Apoorva Joshi, Sr. AI Developer Advocate, MongoDB, Ben Perlmutter, Sr. Engineer, Chatbot Framework, MongoDB\nDate: 2024-06-25\nStart Time: 1530\nAbout: Open Models: In this 2 hour workshop, we will build an AI research agent that can search for research papers, summarize them, and answer questions on topics based on past research. We will use MongoDB as the agent's memory provider and knowledge store, open-source LLMs as the agent’s “brain”, and LangChain to orchestrate the end-to-end agentic workflow.\n\nAttendees will be provided with all the resources required to successfully execute the hands-on portions of the workshop, including a GitHub repository consisting of notebook templates with pseudocode. Attendees will replace the pseudocode with their own code during the workshop. ",
  "Session: AI Music Generation: From Prompt to Production\nPresenters: Phlo Young, Rapper, Independent\nDate: 2024-06-26\nStart Time: 800\nAbout: Multimodality: The rise of AI music generation tools has opened up a world of creative possibilities for musicians and non-musicians alike. This workshop will demystify these tools, providing a hands-on introduction to their capabilities and potential. Participants will learn how to use AI to generate musical ideas, create custom loops and samples, and even compose full songs.\n\n\nIn this workshop we will:\n- Understand the different types of AI music generation tools and their use cases.\n- Get hands-on experience with popular AI music platforms like Suno and Udio.\n- Explore prompt engineering techniques for generating different musical styles and genres.\n- Learn how to refine and customize AI-generated music to your liking.\n- Discuss the ethical and legal considerations surrounding AI music creation.\n\nTakeaway: By the end of the workshop, attendees will have a practical understanding of AI music generation tools and how they can be used to enhance creativity and musical expression. Whether you're a seasoned musician or just starting out, this workshop will equip you with the knowledge and skills to harness the power of AI for making music.\n\nPrerequisites:\n- An account with Suno and Udio (free or paid)\n- No prior musical experience or coding knowledge required (but it helps)\n\nSkill level: Beginner\n\nAssets:\n- https://github.com/YoungPhlo/generating-music-ai-engineer-summer-2024",
  "Session: Using GitHub Copilot to Extend and Build Your Own Copilots\nPresenters: Christina Warren, Senior Developer Advocate, GitHub, Christopher Harrison,  Senior Developer Advocate, GitHub\nDate: 2024-06-25\nStart Time: 900\nAbout: This workshop will be split into 3 one hour blocks: 1. Setup and Introduction to GitHub Copilot -- this will be a brief introduction to GitHub Copilot and how to use it in your workflow. A longer workshop on this topic will be held later in the day. Please create a GitHub account before the workshop if you do not already have one. If you already have GitHub Copilot, you are welcome to use it during the workshop. We will also be able to provide access for individuals who have not yet signed up for GitHub Copilot. 2. Extending GitHub Copilot -- this will be a hands-on workshop where we will walk through how to create a custom GitHub Copilot Extension. We will provide a template that you can use to create your own extension that will work with Visual Studio Code and GitHub Copilot Chat. You will need to have Visual Studio Code installed on your computer to participate in this workshop, alongside the GitHub Copilot Chat preview extension. Links will be provided during the workshop. 3. Building your own custom GPT. Using GitHub Copilot and GitHub Codespaces to build your own custom GPT using OpenAI's Assistants API. This will require your own OpenAI API key.",
  "Session: Knowledge Graphs & GraphRAG: Techniques for Building Effective GenAI Applications\nPresenters: Zach Blumenfeld, AI/ML Product Specialist, Neo4j, Andreas Kolleger, Knowledge Engineer, Neo4j\nDate: 2024-06-25\nStart Time: 1530\nAbout: RAG & LLM Frameworks: Learn about practical graph design patterns and retrieval strategies to more effectively customize GenAI for real-world applications. While GenAI offers great potential, it faces challenges with hallucination and lack of domain knowledge. Graph-powered retrieval augmented generation (GraphRAG) helps overcome these challenges by integrating vector search with knowledge graphs and data science techniques to improve context, semantic understanding, and personalization while facilitating real-time updates. \nYou'll receive detailed coded examples to begin your journey with GenAI and graphs, leaving with practical skills to apply immediately to your own projects.\n\nPrerequisites: This is a hands-on workshop where you can follow along with Jupyter notebooks in Colab.  We will provide links to notebooks at the beginning of the workshop. To follow along please:\n- Bring your laptop\n- Create a Google account ahead of time if you don’t have one already so you can run Colab notebooks.\n- [Prefered] Bring a working openAI API key. We will provide a key for those that do not have one yet. To make a new key, create an OpenAI account or sign in. Next, navigate to the API key page and \"Create new secret key\". Optionally naming the key. Save this somewhere safe, and do not share it with others. We recommend testing your key to make sure it works - see the OpenAI quickstart tutorial for more details. ",
  "Session: Convex workshop tba\nPresenters: Tom Redman, Head of DX, Convex\nDate: 2024-06-26\nStart Time: 800\nAbout: Details tba",
  "Session: Turn Your Idea into an AI Application in Minutes: Quick Start with AI Templates (Repeat)\nPresenters: Pamela Fox, Principal Cloud Advocate (Python), Microsoft, Harald Kirschner, Principal Product Manager, Microsoft\nDate: 2024-06-25\nStart Time: 1530\nAbout: \"Building and deploying generative AI solutions can be challenging and time-consuming, especially for startups with limited resources and expertise. In this workshop, you will learn how to use AI templates and GitHub to quickly prototype and deploy generative AI applications in minutes. AI templates are ready-made solutions that leverage Microsoft Azure Services and GitHub features like GitHub Codespaces and GitHub Actions. You can access AI templates from the Microsoft for Startups Founders Hub, a platform that provides startups with exclusive access to tools, resources, and benefits to help them grow and scale their businesses. By the end of this workshop, you will be able to: \n • Understand the basics of generative AI and its applications for startups \n • Explore the AI templates available on the Microsoft for Startups Founders Hub \n • Select an AI template that matches your idea and customize it to your needs \n • Deploy your generative AI application to a web app or a chatbot\n • Test and iterate on your generative AI application and get feedback from users Prerequisites: \n • A GitHub account \n • A Microsoft Azure account (you can get a free trial or a credit through the Microsoft for Startups program) \n • An Azure subscription with access enabled for the Azure OpenAI Service \n • A basic understanding of generative AI and GitHub (optional)\"",
  "Session: Second Order Effects\nPresenters: Cheng Lou, Member of Technical Staff, Midjourney\nDate: 2024-06-27\nStart Time: 1440\nAbout: Abstract coming soon",
  "Session: The Multimodal Future of Education\nPresenters: Stefania Druga , Research Scientist, Gemini, Google\nDate: 2024-06-27\nStart Time: 1420\nAbout: We will explore how we might use  AI models to combine sounds, images, and videos  and create new learning activities that support critical, creative and counter-factual thinking. Showcase demos using Generative AI (Vertex API, AI studio, LearnML) to detect misconceptions in math learning, support creative coding, create simulations to test scientific hypotheses, curate and sumarize research & identiy blind spots in one’s thinking.  The goal of our demos will be to demonstrate  how mights we use multimodal ai to support learning activities where the agency is balanced between learners and AI and we encourage people to discover the limitations of these technologies while developing a critical use of it, know if, when and how to use it when learning new skills.",
  "Session: Year of Multimodality opening keynote TBA\nPresenters: Logan Kilpatrick, Product Lead, Google AI Studio, Google\nDate: 2024-06-27\nStart Time: 1122\nAbout: null",
  "Session: The Hierarchy of Needs for Training Dataset Development\nPresenters: Chang She, CEO, LanceDB, Noah Shpak, Member of Technical Staff, Character.ai\nDate: 2024-06-27\nStart Time: 1400\nAbout: Training and fine-tuning models depends critically on how you construct your dataset. Part art, part science, we’ll share with you practical lessons in dataset construction at Character AI and how to build a data platform to support rapid iterative refinement of training data. For LLMs, data scale is much larger and workloads are more diverse. This is especially true for multimodal datasets. To deal with these challenges, we'll show you how LanceDB is used in production to solve many pain-points around the storage, management, and querying of large scale AI data.",
  "Session: The era of unbounded products: Designing for Multimodal I/O\nPresenters: Ben Hylak, CPO, Dawn Analytics\nDate: 2024-06-27\nStart Time: 1142\nAbout: \"everything is converging. ai models can now natively understand the same modalities as you. at the same time, AR technology is getting to a place where we are able to experience virtual worlds like never before. how did we get here, where is this going, and how do we build intuitive experiences in the age of unbounded products.\"",
  "Session: State Space Models for Realtime Multimodal Intelligence\nPresenters: Karan Goel, CEO, Cartesia\nDate: 2024-06-27\nStart Time: 1202\nAbout: What are the big breakthroughs required to bring realtime multimodal intelligence to every device in the world? This talk describes the work we're doing at Cartesia on bringing realtime models to life on an entirely new technology stack. I'll describe new research ideas that we developed over the last few years — state space models — that are enabling us to build audio models that are cheaper, faster and higher quality than state of the art approaches.",
  "Session: Substrate Launch: the API for modular AI\nPresenters: Rob Cheung, CEO, Substrate\nDate: 2024-06-27\nStart Time: 1115\nAbout: AI models enable some new and powerful capabilities, but we still need to think of them as functions in larger logical systems, rather than a sort of end-state for software. AI-integrated programs should be built just like any other program: by relating small semantic tasks to each other in order to automate a larger task. Right now, the main problem preventing developers from running 10-20 AI modules on a single user request is an infrastructure one, and that’s what we’re solving. Large companies like Google have built internal infrastructure and SDKs to enable this, but we’re offering this capability to any developer.",
  "Session: No more bad outputs with structured generation\nPresenters: Rémi Louf, CEO, .txt (Outlines)\nDate: 2024-06-26\nStart Time: 1135\nAbout: JSON, prompt formatting, hallucinations. If you feel uncomfortable, you have probably had to implement complex solutions to circumvent these problems. What if there was a way to increase the reliability of Large Language Models at no cost? Enter structured generation. In this talk we will explore how the output of models can be steered at no extra cost, why this improves their efficiency and accuracy significantly and makes generation less sensitive to the specifics of the prompt. By the end of the talk, we'll understand how we can start benefiting from this breakthrough today by using the open source library Outlines.",
  "Session: Building SOTA Open Weights Tool Use: The Command R Family\nPresenters: Sandra Kublik, Developer Advocate, Cohere\nDate: 2024-06-26\nStart Time: 1155\nAbout: We opened model weights for Command R and R+, and the response was incredible. This talk will showcase the community's innovative projects and our journey to building SOTA multi-step tool use proficiency with the R family. We will also share the design decisions that make the R family unique and effective.",
  "Session: Fixing bugs in Gemma, Llama & Phi-3\nPresenters: Daniel Han, CEO, Unsloth\nDate: 2024-06-26\nStart Time: 1420\nAbout: The story behind our 8 bug fixes for Gemma, multiple tokenization fixes for Llama 3, a sliding window bug fix and Mistral-fying Phi-3, and learn about how we analyse and find and fix bugs in open source models. Learn also how we make finetuning 2x faster for all these models",
  "Session: Decoding Mistral AI's Large Language Models\nPresenters: Devendra Chaplot, Research Scientist, Mistral\nDate: 2024-06-26\nStart Time: 1115\nAbout: In this talk, Devendra Singh Chaplot, Research Scientist at Mistral AI will explore the building blocks and training strategies that power Mistral AI’s large language models. It will feature Mistral AI's open-source models, Mixtral 8x7B and Mixtral 8x22B, which are based on a mixture-of-experts (MoE) architecture and released under the Apache 2.0 license. The presentation will also provide guidance on utilizing Mistral \"La Plateforme\" API endpoints and offer a preview of upcoming features.",
  "Session: Google Gemma talk TBA\nPresenters: Kathleen Kenealy, Staff Research Engineer, Google\nDate: 2024-06-27\nStart Time: 1400\nAbout: talk tba",
  "Session: Everything you need to know about Finetuning and Merging LLMs\nPresenters: Maxime Labonne, Senior Staff ML Scientist, Liquid AI\nDate: 2024-06-26\nStart Time: 1440\nAbout: Fine-tuning LLMs is a fundamental technique for companies to customize models for their specific needs. In this talk, we will cover when fine-tuning is appropriate, popular libraries for efficient fine-tuning, and key techniques. We will explore both supervised fine-tuning (LoRA, QLoRA) and preference alignment (PPO, DPO, KTO) methods.",
  "Session: Training Albatross: An Expert Finance LLM\nPresenters: Leo Pekelis, Chief Scientist, Gradient\nDate: 2024-06-27\nStart Time: 1420\nAbout: The challenge with financial agents successfully completing complex workflows like tabular reasoning or sentiment analysis often comes down to the reliability of executing numerous chained tasks together. Establishing the p99s necessary has to happen at the model level, yet most finance domain-specific LLMs are either only pre-training (BloombergGPT) or using supervised fine-tuning (FinBERT). \n\nThis presentation reveals how we transformed an open-source model into Albatross (https://huggingface.co/gradientai/v-alpha-tross), capable of performing at the top of the leaderboard on chat as well as domain-specific tasks. Our journey involved an intensive data pipeline and training regiment, incorporating a combination of continual pre-training, fine-tuning, and preference optimization, to customize the model for the intricacies of financial tasks. We'll share our insights on overcoming the execution hurdle, which is often the downfall of AI projects in specialized domains.",
  "Session: Navigating RAG Optimization with an Evaluation-Driven Compass\nPresenters: Atita Arora, Solution Architect, Qdrant, Deanna Emery, Founding AI Researcher, Quotient\nDate: 2024-06-26\nStart Time: 1142\nAbout: Retrieval Augmented Generation (RAG) has become a cornerstone for integrating domain-specific content and addressing hallucinations in AI applications. As the adoption of RAG solutions intensifies across industries, a pressing challenge emerges: understanding and identifying where within the complex RAG framework changes and improvements can be made. This talk delves into the methodology of extracting crucial indicators from your RAG pipeline, empowering informed decision-making during experimentation. Join us as we navigate an end-to-end process for RAG experimentation and evaluation, offering insights into optimizing performance and addressing hurdles along the RAG implementation journey.",
  "Session: The Adversarial Path to the Personal Assistant\nPresenters: Sumit Agarwal, CEO, Ario AI\nDate: 2024-06-26\nStart Time: 1432\nAbout: \"Despite their trillions of tokens of training data, GPT4 and others models can’t answer a single question about us as unique individuals. The personal AI assistant we all want surely has to know us as individuals, right? Today’s AI assistants either give us generic information, or require significant input from us before providing useful personalized assistance. Isn’t there a better path? Of course there is. In this talk, we’ll discuss our implementation of a personal, private, proactive AI assistant that begins its relationship with you by downloading your transaction logs from major B2C sites (think of Google, Facebook, Amazon, Doordash, Strava, Uber and dozens of others) to your local device. By building a RAG system using this data, our personal AI assistant becomes useful immediately, without requiring significant user input. Learn how a modest amount of very powerful personal data can unlock the power and potential of personal AI assistants.\"",
  "Session: GraphRAG: The Marriage of Knowledge Graphs and RAG\nPresenters: Emil Eifrem, CEO, Neo4j\nDate: 2024-06-26\nStart Time: 1412\nAbout: A famous poet once said \"Natural language is most powerful when it can draw from a rich context.\" Ok fine, I said that. But that's true of both poetry, and of LLMs! Well, Knowledge Graphs excel at capturing context. How can combining Knowledge Graphs with RAG – an emerging technique known as GraphRAG – give context to your RAG application, and lead to more accurate and complete results, accelerated development, and explainable AI decisions? This talk will go deep on the why and how of GraphRAG, and where best to apply it. You’ll get concepts, examples, and specifics on how you can get started. You’ll walk away with an understanding of how GraphRAG can improve the context you pass to the LLM and the performance of your AI applications.",
  "Session: Going beyond RAG: Extended Mind Transformers\nPresenters: Phoebe Klett, Machine Learning Engineer, Normal Computing\nDate: 2024-06-26\nStart Time: 1202\nAbout: Retrieval Augmented Generation is such a hack. Why would an embedding of your prompt coincide with the documents needed to answer it? Meanwhile Transformers already have a key/query mechanism built in! In this talk, we'll introduce Extended Mind Transformers, a new flavor of transformer that allows the model to select and attend to the most relevant information at each generation step. We demonstrate EMT's state-of-the-art performance and discuss important design decisions for long context applications.",
  "Session: How to Make AI Capable of Nobel Prize Discoveries - A Thing about Scientific Reasoning\nPresenters: Hubert Misztela , AI Researcher/Director of Data Science, Novartis \nDate: 2024-06-26\nStart Time: 1452\nAbout: \"Do you remember that feeling when you realized who was Jon Snow's mother? Or who was the Batman really? Those 'aha' moments define scientific reasoning: of many steps and non-obvious. \n\nEven though the scientific discovery using LLMs is becoming more popular recently, there is little if any discussion about high level reasoning process behind breakthroughs in science.\n\nSome of the discoveries like RNA interference required connecting of distanced areas of biology, described in different journals and with distinct vocabulary. \nIn this talk we would like to discuss if LLMs would be able to spot those novel relationships behind phenomenas from distanced areas? What would it take: RAG, Agentic RAG or fully fledged AI agent?\n\nWe will first try to classify problems tackled by RAGs. Then we would define a new family of NLP problems related to the scientific discovery and propose a template for benchmarking of thereof.\nWe would discuss them on the examples of Nobel Prize discoveries. \nThen the question would be if and how RAGs or more general AI Agents might help us in tackling those problems, so we will try to entertain you with some\nattempts to solve it.\"",
  "Session: EyeLevel Launch: Your RAG is Tripping, Here's the Real Reason Why\nPresenters: Benjamin Fletcher, CEO, EyeLevel.ai\nDate: 2024-06-26\nStart Time: 1400\nAbout:  95% of RAG hallucinations are generated by the RAG, not the LLM. But why? In this talk, we'll discuss the hard data engineering problems of building highly accurate RAG systems and how to fix them. You'll see how companies like Air France are getting 95% accuracy or better.",
  "Session: RAG and the MongoDB Document Model\nPresenters: Ben Flast , Director of Product, MongoDB\nDate: 2024-06-26\nStart Time: 1122\nAbout: In this talk, we will explore the cutting-edge techniques for Retrieval Augmented Generation with MongoDB. We will focus on leveraging Vector Search, specifically Atlas Vector Search, over MongoDB data to improve information retrieval and generation processes.\n\nWe will show how to build a RAG system using a Parent Child Retrieval Strategy to enable more efficient and accurate retrieval of relevant information. Additionally, we will show how all of this can be done within the MongoDB document model rather than relying on implementing these relationships in the application layer. And finally, we will introduce the concept of Search Nodes which enable you to serve vector search workloads at scale.\n\nThis talk is aimed at developers, ML engineers, and data scientists interested in building AI powered experiences with RAG. By the end of the session, attendees will have a solid understanding of how Retrieval Augmented Generation, Vector Search, and MongoDB can be leveraged to build innovative and scalable AI-powered applications.\n",
  "Session: Trunk Tools Launch: Disrupting the $15 Trillion Construction Industry with Autonomous Agents\nPresenters: Dr. Sarah Buchner, CEO, Trunk Tools\nDate: 2024-06-26\nStart Time: 1407\nAbout: Dr. Sarah Buchner, Founder & CEO of Trunk Tools, envisions a future for construction where an army of AI agents works on behalf of our users. We are currently deploying an agent every 45 days: our Q&A agent, TrunkText, is already saving field professionals 1-2 hours every day. We believe that ~$2.5 Trillion of the construction industry can be automated with Trunk Tools.",
  "Session: Vector Search is NOT All You Need \nPresenters: Henry Weller, Product Manager, MongoDB\nDate: 2024-06-26\nStart Time: 1100\nAbout: In this talk, we'll talk through how developers are getting the most out of Atlas Vector Search through intelligent data modeling of unstructured data. This enables both iterating on your search problem and operating your search system in a way that seamlessly syncs with your original source data. We will also discuss how to consider the capabilities of embedding and chat completion models so that you can effectively ingest data into MongoDB in a way that makes it easily searchable.",
  "Session: Using agents to build an agent company\nPresenters: João Moura, CEO, crewAI\nDate: 2024-06-27\nStart Time: 1202\nAbout: \"This talk is about a simple idea: Everyone should be able to use AI to make cool stuff.\n\nWhen I started making crewAI, a framework to build AI Agents, I didn't know just how much it would change the way I work. \nThis isn't just a chat about building AI Agents; it's a story about how these tools helped us grow our business and how they can help you too. \n\nI'll share our adventure with crewAI, showing how we used AI to solve problems, save time, and come up with new ideas. It's a journey of discovery and making things better with AI, showing everyone that they can use AI in their work and projects.\"",
  "Session: Building Reliable Agentic Systems\nPresenters: Eno Reyes, CTO, Factory\nDate: 2024-06-27\nStart Time: 1142\nAbout: Agentic system design is a rapidly evolving and intellectually fascinating field, with huge potential for transforming how software is used across industries. Unlike traditional software, agentic systems rely on non-deterministic and oftentimes difficult to predict decision making. Taking inspiration from fields like robotics, cybernetics, and biology, we can start to develop intuitions around how to build systems that are ~more~ reliable than the sum of their individual stochastic parts.",
  "Session: Personality-Driven Development: Exploring the Frontier of Agents with Attitude\nPresenters: Benjamin Stein, CEO, Perpetual\nDate: 2024-06-27\nStart Time: 1440\nAbout: Meet Circuitrix, the sassy robot who schedules meetings, Hootie McHootface, the whimsical owl who transcribes calls, and Zarplo, the sycophantic code-reviewing martian -- AI agents with personalities as unique as their workflows. \n\nIs giving AI agents human-like traits merely a marketing gimmick? Or does it fundamentally transform and improve user adoption and interaction? We'll explore the impact of anthropomorphizing AI agents on user engagement, and share insights from letting end-users completely customize their own agents’ personalities. \n\nDiscover the engineering practices required to develop agents with unique personas, the technical challenges debugging a product with infinite(!) customizability, and why you may never say the phrase \"works on my machine\" ever again. Get ready to rethink the relationship between AI and users in this deep dive into the world of personality-driven agent design.\n",
  "Session: Which Jobs Can Be Replaced Today\nPresenters: Fryderyk Wiatrowski, Co-founder, Zeta Labs, Peter Albert, Co-Founder, Zeta Labs\nDate: 2024-06-27\nStart Time: 1400\nAbout: The founders of Zeta Labs will provide an update on the progress in autonomous agent development, discussing its alignment with the timeline for replacing humans in their current jobs. Additionally, they will highlight how these agents represent a crucial milestone towards achieving Artificial General Intelligence (AGI)",
  "Session: Giving a Voice to AI Agents\nPresenters: Scott Stephenson, CEO, Deepgram\nDate: 2024-06-27\nStart Time: 1420\nAbout: Voice AI technology has evolved significantly in recent years, transitioning from simple command-response systems to more sophisticated natural conversational agents powered by Large Language Models (LLMs). This progression in voice AI is being driven by advances in core technologies such as foundational AI models, dramatically transforming interactions between humans and machines. Notable improvements include advanced automatic speech recognition and breakthroughs in human-like speech synthesis, all integrated with the deep language comprehension provided by LLMs. These developments have culminated in powerful, autonomous systems that interact through spoken language exclusively. During the session, Scott Stephenson, Founder and CEO of Deepgram, will explore the fundamental principles and best practices for crafting responsive, realistic, and captivating AI agents. He will delve into topics such as natural language processing and the design of multimodal interactions. Attendees will gain insights into the principal design challenges and key considerations involved in developing voice agents capable of managing complex conversations and providing context-sensitive responses on par with human speakers.",
  "Session: Claude plays Minecraft: Introducing a real world serverless AI to a virtual world\nPresenters: Derek Bingham, Senior Developer Advocate, AWS\nDate: 2024-06-27\nStart Time: 1122\nAbout: Not Chatbots again! Not today, thank you!\n\nImagine a world where AI does more than just chat—it thinks, solves, and acts. Enter the realm of Minecraft, where virtual landscapes become the perfect proving ground for the next generation of autonomous agents.\n\nThis deep dive session takes you on an adventure beyond the ordinary, showcasing how we've engineered an AI entity capable of reasoning, problem-solving, and executing tasks in Minecraft. \n\nLeveraging the power of Amazon's Bedrock, Lambda, SNS, and a suite of AWS serverless technologies, paired with the latest Claude 3 model from Anthropic, we reveal the full potential of AI beyond the confines of chatbots.\n\n\nDiscover how these serverless solutions empower our AI to interact with, adapt to, and transform its environment in real-time, providing a glimpse into the future of autonomous agents in both virtual and real-world applications. Join us as we navigate the intricacies of serverless AI architecture, demonstrating its practical implications, block by block.",
  "Session: AI Platform engineering - the pattern to scale across all engineering\nPresenters: Patrick Debois, VP Engineering, Jedi, Independent\nDate: 2024-06-26\nStart Time: 1148\nAbout: \"AI engineers are great, but to scale it out to the organisation you need an AI Platform team.\n\nSimilar to introducing Agile and DevOps companies have pilot projects to release their first genAI features. They would bring in people that have an affinity for both AI and applications together to form the first change agent in a company. Once you have a few teams, you notice that there is shared AI infrastructure, you need enablement and governance across. This pattern has been used to introduce Cloud, Security and Developer Experience. \n\nIn this talk we highlight:\n- the shared components of the AI stack: proxies, caching, testing, feedback collection, guardrails, ...\n- the steps (and struggles) to enable this across the whole engineering (hackathons, training, abstractions)\n- how it fits in the existing SDLC workflow and processes (testing , versioning, observability , security)\n- how we can leverage the knowledge of all platform teams together (cloudops, secops , developer experience , data platform and ai platform) for dealing with security , permissions and performance\"",
  "Session: E-Values: Evaluating the Values of AI\nPresenters: Sheila Gulati, Managing Director, Tola Capital\nDate: 2024-06-27\nStart Time: 1433\nAbout: LLM evaluation is one of the most important questions for AI engineers today. Existing benchmarks and tools often fall short in addressing the complexities of LLM evaluation in real-world production settings, the lack of a robust LLM evals tool presents a significant obstacle for AI engineers to move LLM applications from pilot to production. As LLMs find widespread utility across domains, the need for domain-specific metrics and comprehensive test sets also grows. Developing such evaluation systems demands deep AI expertise and understanding of developer user experience, few existing solutions meet these requirements. Successful LLM evaluation platforms will 1) prioritize integration into the development lifecycle, 2) automate test set generation with the right distribution and diversity to capture a wide range of real-world edge cases. and 3) continuously monitor and evaluate model performance in production, often in real-time. While LLM evaluation is still in its infancy, we see this area as one of the most exciting opportunities for startups to innovate in.",
  "Session: The ROI of AI: Why You Need Eval Frameworks\nPresenters: Beyang Liu, CTO, Sourcegraph\nDate: 2024-06-26\nStart Time: 809\nAbout: There has been a ton of hype about AI's applications in software development, but leaders must look beyond the hype to assess the ROI for their organizations. We'll cover some quantitative and qualitative frameworks that have proven useful for our customers, highlight the benefits and drawbacks of popular metrics in use, and share the themes that have emerged as important pillars of the value prop for AI dev tools. I'll also share a vision for where the next 18 months of AI will lead in software development.",
  "Session: Mastering LLM Inference Optimization: From Theory to Cost-Effective Deployment\nPresenters: Mark Moyou, Sr. Data Scientist, NVIDIA\nDate: 2024-06-26\nStart Time: 1121\nAbout: \"LLM inference is not your normal deep learning model deployment nor is it trivial when it comes to managing scale, performance and COST. Understanding how to effectively size a production grade LLM deployment requires understanding of the model(s), the compute hardware, quantization and parallelization methods, KV Cache budgets, input and output token length predictions, model adapter management and much more. \n\nIf you want to deeply understand these topics and their effects on LLM inference cost and performance you will enjoy this talk. \n\nThis talk will cover the following topics:\n- Why LLM inference is different to standard deep learning inference\n- Current and future NVIDIA GPU overview - which GPU(s) for which models and why\n- Understanding the importance of building inference engines\n- Deep recap on the attention mechanism along with different types of popular attention mechanisms used in production\n- Deep dive on KV Cache and managing KV Cache budgets to increase throughput per model deployment\n- Parallelism (reducing latency) - mainly tensor parallelism but data, sequence, pipeline and expert parallelism will be highlighted\n- Quantization methods on weights, activations, KV Cache to reduce engine sizes for more effective GPU utilization\n- Increasing throughput with inflight batching and other techniques\n- Detailed performance analysis of LLM deployments looking at Time to first token, inter-token latencies, llm deployment characterizations, and more  that can help reduce deployment costs\n\nThe main inference engine referenced in the talk with TRT-LLM and the open-source inference serve NVIDIA Triton.\"",
  "Session: Decade-Long Abstractions: How to futureproof your LLM Ops at Scale\nPresenters: Raza Habib, CEO, Humanloop\nDate: 2024-06-27\nStart Time: 1121\nAbout: null",
  "Session: Productionizing GenAI Models – Lessons from the world's best AI teams\nPresenters: Lukas Biewald, CEO, Weights & Biases\nDate: 2024-06-26\nStart Time: 829\nAbout: AI is poised to add $15.7 trillion to the global economy by 2030, with generative AI at the forefront of this revolution, marking a transformative shift across sectors. In his talk, Lukas Biewald will unpack the impact and potential of generative AI models and share practical insights learned from the best ML teams in the world who're building and implementing AI in production. He will share specific insights on deploying GenAI models into real-world applications, emphasizing LLM evaluation, dataset management, model experimentation and optimization. This session is a call to action for ML teams looking to leverage AI's full potential responsibly, and looking to expedite putting AI into production.",
  "Session: Cooking with fire without burning down the kitchen\nPresenters: Dominik Kundel, Head of Product & Design, Emerging Tech & Innovation, Twilio\nDate: 2024-06-27\nStart Time: 1406\nAbout: Over the last 2 years the capabilities of LLM have been developing at a rapid pace and R&D organizations in almost every industry are expected to determine their \"AI strategy\" while balancing existing non-AI customer needs  and a tighter financial environment. For some, recent AI developments might even pose a disruptive shift for their products and company, but how do you balance rapid prototyping and exploration of these disruptive technologies with catering to your current user base to avoid the Innovator's Dilemma? Should you add AI to every product team's roadmap or form a dedicated AI team? How do you experiment with entirely new AI endeavors without risking your current customer base? In other words, how do you cook with fire without burning down the kitchen?  \n\nIn this discussion round, Dominik Kundel will share how Twilio has been tackling some of these challenges, their learnings and what changes/iterations they have been going through to address those learnings, followed by an open discussion for others to share their learnings.",
  "Session: Hiring & Building an AI Engineering Team\nPresenters: Dr Bryan Bischof, Head of AI , Hex\nDate: 2024-06-27\nStart Time: 1148\nAbout: null",
  "Session: The AI Production Journey: Breaking the Code\nPresenters: Philip Rathle, CTO, Neo4j\nDate: 2024-06-26\nStart Time: 1406\nAbout: When your mindblowing prototype meets the real world, GenAI projects can get stuck on their way to production. Whether it’s accuracy, explainability, compliance, cost, privacy, security, skills, politics, culture, or something else, this session is an open conversation where participants will share their experiences of getting stuck… and unstuck!\n\nLet’s explore the “getting to production” problem together, and learn from each other’s successes and challenges to break the AI production code.",
  "Session: LLM Safeguards: Security, Privacy, Compliance, Anti-Hallucination\nPresenters: Daniel Whitenack, CEO, Prediction Guard\nDate: 2024-06-27\nStart Time: 1500\nAbout: description tba",
  "Session: Scaling AI in Education: A Khanmigo case study\nPresenters: Shawn Jansepar, Director of Engineering, Learning & AI Platform, Khan Academy\nDate: 2024-06-26\nStart Time: 1215\nAbout: \"In this presentation, I will explore Khan Academy's journey to become an AI-first organization, focusing on our AI Tutor and Teacher Assistant, Khanmigo. This case study will cover the strategic evolution from conception, through to launch, and continuous iteration and refinement.\n\nKey Highlights:\n\n- Strategic partnership: The collaboration with OpenAI to launch Khanmigo alongside GPT4, going from prototype to fully launched product in 3 months time. I will delve into the why and how behind our decision to partner with OpenAI, and to leverage generative AI in our product.\n- Cultural shift in product development: The transition from our previous, more traditional product development approach to a highly experimental, prototype-driven culture. This section will highlight how we embedded AI across all teams to enhance our mission, moving beyond isolated AI projects to fully integrate AI into our operational fabric.\n- Khanmigo in action: An in-depth look at Khanmigo's functionality and its solution to real-world challenges faced by students and teachers, coupled with it's impact in real classrooms around the US.\n- Ongoing technical challenges and scaling: An overview of the technical obstacles encountered in scaling and maintaining quality as we continued to add more users.\n- Ethical considerations and AI safety: How we thought of AI safety in the context of the classroom, and delivered on an experience that parents and educators trust. \n- Pilot programs and iterative learning: Insights from our pilot programs across various school districts, focusing on how we've used feedback and data to refine and enhance Khanmigo's capabilities.\"",
  "Session: Cohere for VPs of AI\nPresenters: Vivek Muppalla, Director Of Engineering, Cohere\nDate: 2024-06-27\nStart Time: 1215\nAbout: Executive briefing and private Q&A for VPs of AI",
  "Session: OpenAI for VPs of AI\nPresenters: Shyamal Anandkat, Head of GTM, OpenAI, Toki Sherbakov, Head of Solutions Architecture, OpenAI\nDate: 2024-06-26\nStart Time: 1433\nAbout: An executive briefing on OpenAI's Enterprise offerings and roundtable discussion for VPs of AI.",
  "Session: Lessons from the Trenches: Building LLM Evals That Work IRL\nPresenters: Aparna Dhinkaran, CPO, Arize\nDate: 2024-06-27\nStart Time: 1420\nAbout: With nearly two-thirds of enterprise developers planning production deployments of large language models this year, LLM evaluation has never been more important. LLM evaluation is also an area where confusion reigns, starting with ambiguity around what “LLM evals” even means. Often, LLM model evaluation – quantifying general fitness (i.e. on the Hugging Face leaderboard) –  is conflated with task-specific LLM system evaluation. And while many foundation model providers offer their own evals, AI engineers building LLM systems designed to plug into many models or tools need a way to objectively evaluate both different foundation models and their own systems with rigorous techniques. In this session, Arize AI founder Aparna Dhinakaran will release research onstage and walk attendees through real life examples of building an LLM Eval from scratch. This session will build on multiple research pieces that have garnered millions of views across social platforms, diving into techniques to build out robust LLM evals and ultimately gain a better understanding of the limits of LLM capabilities. Want to build your own LLM task evals for a specific use case leveraging open source tools? Want to see the latest research on which foundation models your company should be using for specific use cases? You won’t want to miss this session!",
  "Session: How to construct domain-specific LLM evaluation systems.\nPresenters: Hamel Husain, AI Engineer, Parlance Labs, Emil Sedgh, CTO, Rechat\nDate: 2024-06-27\nStart Time: 1135\nAbout: \"Many failed AI products share a common root cause: a failure to create robust evaluation systems.  Evaluation systems allow you to improve your AI quickly in a systematic way and unlock superpowers like the ability to curate data for fine-tuning.  However, many practitioners struggle with how to construct evaluation systems that are specific to their problems. \n\nIn this talk, we will walk through a detailed example of how to construct domain-specific evaluation systems.\"",
  "Session: What It Actually Takes to Deploy GenAI Applications to Enterprises\nPresenters: Arjun Bansal, CEO, Log10, Trey Doig,  CTO, Echo AI\nDate: 2024-06-27\nStart Time: 1440\nAbout: Join Alexander Kvamme and Arjun Bansal as they recount Echo AI’s journey rolling out its conversational intelligence platform to billion-dollar retail brands. They’ll discuss navigating LLM accuracy issues as well as what needed to happen at the application and infrastructure layers in order to successfully deploy at enterprise scale.",
  "Session: Judging LLMs\nPresenters: Alex Volkov, AI Evangelist, Weights & Biases\nDate: 2024-06-27\nStart Time: 1115\nAbout: All rise! The honorable LLM Judge presiding. On the docket today, many cases of AI Engineers building with LLMs, without the ability to iterate, evaluate and improve their products. ",
  "Session: How Zapier Builds AI Products and Features With the Help of Braintrust\nPresenters: Ankur Goyal, CEO, Braintrust, Olmo Maldonado, Sr. AI Engineer, Zapier\nDate: 2024-06-27\nStart Time: 1155\nAbout: Zapier is the #1 workflow automation platform for small and midsize businesses, connecting to more than 7,000 of the most popular work apps. We were also one of the first companies to build and ship AI features into our core products. We've had the opportunity to work with Braintrust since the early days of the product, which now powers the evaluation and observability infrastructure across our AI features.  \n\nWe’ll walk through a couple of our projects – AI Zap Builder and Zapier Copilot – and how we built them from the ground up with evals and observability in mind. Hopefully, you can walk away with a few of our learnings from operating these projects at scale while systematically improving their performance.",
  "Session: The GenAI Maturity Curve (or: You Probably Don’t Need Fine-Tuning)\nPresenters: Kyle Corbitt, CEO, OpenPipe\nDate: 2024-06-27\nStart Time: 1400\nAbout: Simple instruction prompting? Few-shot examples? Fine-tuning? How do you decide when to do each? In this talk we’ll discuss the emerging concept of the GenAI maturity curve and define the steps along it. We’ll also discuss the concrete triggers you should watch for to indicate that you’re ready to move up to the next step.\n\nAt OpenPipe we’ve helped customers fine-tune thousands of models (and redirected thousands more who hadn’t hit the trigger points). Let’s talk about how to speed-run that journey!",
  "Session: Cursor: Humans + AI for Maximally Productive Software Engineering\nPresenters: Aman Sanger, Co-founder, Anysphere (Cursor)\nDate: 2024-06-26\nStart Time: 1155\nAbout: How do you maximize productivity? By making humans and AI work **together**. At Anysphere, we’ve been prototyping, researching, and building a human+AI productivity-maximizing tool for more than a year — Cursor. This talk will be a tour of what we’ve tried, what we’ve learned, and what we believe, presented as a sequence of concrete experiments. Expect some alpha, lots of failed attempts, and a unique glimpse into how we’re working to make you, the human software engineer, into the superhuman creator-of-worlds you’re meant to be.",
  "Session: Scott Wu and the Making of Devin by Cognition AI\nPresenters: Scott Wu, CEO, Cognition\nDate: 2024-06-27\nStart Time: 1440\nAbout: Meet Devin, a state-of-the-art AI software agent that helps developers save time and achieve more. Scott Wu, co-founder and CEO of Cognition AI, demos its capabilities and shares some of the lessons that he and his team have learned while building Devin.",
  "Session: Self-Evolving Code with AI: Enhancing Quality and Security in CI\nPresenters: Gunjan Patel, Director of Engineering, Palo Alto Networks\nDate: 2024-06-26\nStart Time: 1440\nAbout: Learn how AI can enable code to self-improve in readability and security. This session explores the integration of AI into CI/CD pipelines with innovative prompting techniques for improving variable names, automating code comments, adding unit tests, and autonomously identifying and fixing security vulnerabilities. Discover practical methods for integrating AI with developer workflows, resulting in code that evolves and improves with minimal manual intervention. This approach makes software development more efficient and secure. Attendees will walk away with a plug-and-play CI template with a Bring-Your-Own-LLM option that can be integrated into their own CI pipelines.",
  "Session: The AI emperor has no DAUs: why most devs still don't use code AI\nPresenters: Quinn Slack, CEO, Sourcegraph\nDate: 2024-06-26\nStart Time: 1400\nAbout: Despite the big potential productivity increases proven from several years in the market, the embarrassing truth is that most developers in the world never or rarely use AI while coding. With hundreds of billions of dollars in upstream AI investments betting on insatiable inference demand, this is a big risk—but also a big opportunity that's not yet priced in, if you believe adoption will accelerate. Quinn Slack, the CEO/cofounder of Sourcegraph, presents this problem and shares solutions for other AI application builders and foundation model companies from lessons learned at Sourcegraph building Cody, the AI coding assistant that is #2 in revenue.",
  "Session: Code Generation and Maintenance at Scale\nPresenters: Morgante Pell, CEO, Grit\nDate: 2024-06-26\nStart Time: 1420\nAbout: AI agents show incredible promise, but have a hard time dealing with existing large-scale codebases. This talk will show examples of how LLMs fail when not given the proper tools and practical demonstrations of how pre-LLM tools already make developers superhuman. Explore a concrete set of challenges around user interfaces for AI and a vision for what superintelligent developer assistants might look like.",
  "Session: GitHub Next Explorations\nPresenters: Rahul Pandita, Automated Software Engineering Researcher, GitHub\nDate: 2024-06-26\nStart Time: 1115\nAbout: In this session, we'll talk about current explorations by GitHub Next including Copilot Workspace a copilot native dev environment for getting started with everyday tasks.",
  "Session: Unlocking Success: Synthesized Founders Share Insights on Partnering with Microsoft for Business Growth\nPresenters: Nicolai Baldin, CEO, Synthesized.io\nDate: 2024-06-26\nStart Time: 1510\nAbout: Come hear from the founders of Synthesized AI and how they partner with Microsoft in growing their business!",
  "Session: Neo4j LLM Knowledge Graph Builder: Unstructured Data to Actionable Insights in Minutes\nPresenters: Alison Cossette, Data Science Advocate, Neo4j\nDate: 2024-06-26\nStart Time: 830\nAbout: Drowning in unstructured text data? The Neo4j LLM Knowledge Graph Builder is your lifeline. This powerful application transforms your PDFs, web pages, and YouTube videos into structured knowledge graphs, enabling you to uncover hidden insights and make data-driven decisions quickly.\nBy leveraging advanced ML models and Neo4j's graph database, the Knowledge Graph Builder streamlines the extraction of entities and relationships from your unstructured data. Connect, upload, and visualize your data as a comprehensive knowledge graph in just a few clicks.",
  "Session: Building production RAG systems at scale (with 10s of millions users)\nPresenters: Nikhil Thota, Member of Technical Staff, Perplexity\nDate: 2024-06-26\nStart Time: 1030\nAbout: null",
  "Session: Multi-model, multimodal, and multi-agent innovations in Azure AI\nPresenters: Cedric Vidal, Principal AI Advocate, Microsoft\nDate: 2024-06-26\nStart Time: 1230\nAbout: Explore GPT-4, multi-modality, and demos integrating sight and language with Dall-E and Whisper. Learn about developer tools, AI assistants, scalable applications, and customization. Focus on responsible AI, data privacy, and security with Azure. Featuring interactive demos and stories, this session is perfect for developers and innovators.",
  "Session: Building Your AI Stack with MongoDB, Cohere, LlamaIndex, and Together AI\nPresenters: Apoorva Joshi, Sr. AI Developer Advocate, MongoDB, Jerry Liu, CEO, LlamaIndex, Vivek Muppalla, Director Of Engineering, Cohere, Heejin Jeong , Principal AI PM, Together\nDate: 2024-06-27\nStart Time: 1510\nAbout: RAG & LLM Frameworks: This panel will feature a 30-minute discussion featuring founders and engineering leaders from four companies leading the way in AI right now — MongoDB, Cohere, LlamaIndex, and Together AI. We will have 10 minutes toward the end for the audience to ask questions to the panelists. During the discussion, panelists will share insights into the following:\n\n- Origins of the company, identifying the problem space \n- What an ideal AI stack looks like today\n- Main use cases of their products\n- Favorite community projects that use their products\n- Challenges with taking LLM applications from prototype to production\n- What will the next few years in AI look like?</u>",
  "Session: RAG at scale: production-ready GenAI apps with Azure AI Search\nPresenters: Pablo Castro, Distinguished Engineer, Microsoft\nDate: 2024-06-27\nStart Time: 1510\nAbout: If 2023 was the year of GenAI prototypes, 2024 is the year these apps go into production. In this session we’ll demo how Azure AI Search combines the best RAG capabilities for GenAI apps at any scale, without compromising cost or performance. We will share the latest product updates, including increased storage limits, advanced capabilities for detailed retrieval pipeline control, built-in support for content beyond text, and re-ranking improvements to boost quality of responses.",
  "Session: Creating and scaling your own custom copilots with Azure AI Studio\nPresenters: Hanchi Wang, Software Engineer Lead, Microsoft\nDate: 2024-06-26\nStart Time: 1257\nAbout: Custom copilots are evolving from simple LLM+data retrieval augmented generation (RAG) solutions into more complex solutions with multiple interoperating APIs, models, metaprompts and grounding data. In this session, we’ll talk about these emerging patterns and show how Azure AI Studio and Promptflow empowers developers to build multi-agent copilot solutions. Discover advanced features such as debugging tools and security measures for developing intelligent, scalable, and safe AI solutions",
  "Session: Knowledge is the New Uranium \nPresenters: Ben Perlmutter, Sr. Engineer, Chatbot Framework, MongoDB\nDate: 2024-06-26\nStart Time: 1332\nAbout: RAG & LLM Frameworks: It's long been said that \"data is the new oil\". With the recent rise of generative AI technologies, we have a new event more precious digital resource fueling the digital economy: knowledge. Retrieval-augmented generation (RAG) has presented a first generative AI use case for organizations to use their knowledge resources, like documentation, knowledge bases, and code repositories. This talk explores various other ways that organizations can use the knowledge resources they ingest for RAG to fuel growth and productivity. Use cases for knowledge resources covered in this presentation include: traditional natural language processing, fine-tuning models, and creating knowledge APIs for AI agents to consume. Attendees will come away from this talk with actionable guidance on how they can leverage their knowledge resources for maximum efficacy.",
  "Session: Vector Search is NOT All You Need \nPresenters: Henry Weller, Product Manager, MongoDB\nDate: 2024-06-27\nStart Time: 1327\nAbout: RAG & LLM Frameworks: In this talk, we'll talk through how developers are getting the most out of Atlas Vector Search through intelligent data modeling of unstructured data. This enables both iterating on your search problem and operating your search system in a way that seamlessly syncs with your original source data. We will also discuss how to consider the capabilities of embedding and chat completion models so that you can effectively ingest data into MongoDB in a way that makes it easily searchable.",
  "Session: Building AI Copilot, ERP, and Knowledge Graph startups — Insights from users building Gen AI apps\nPresenters: Prakul Agarwal, Sr. Product Manager, Machine Learning, MongoDB, Gabriel Paunescu , CEO, Naologic, Chris Rec, Co-Founder, WhyHow.AI, Karthik Suresh , CPTO, Ignition\nDate: 2024-06-26\nStart Time: 1510\nAbout: RAG & LLM Frameworks: This will be a 30-minute panel discussion between one MongoDB representative and three of our customers who are actively building AI applications. We will have 15 minutes towards the end for the audience to ask questions to the panelists. During the discussion, panelists will share insights into the following:\n-How their role at the company has changed in the past year\n-Their preferred AI stack\n-What AI features they are currently working on\n-Challenges with taking LLM applications from prototype to production\n-Most common user pain points, how they collect and incorporate user feedback\n-Metrics to measure success and monitoring",
  "Session: Building Time Series Foundation Models: The Journey to Success with Nixtla and Microsoft\nPresenters: Azul Garza, CTO & Co-Founder, Nixtla\nDate: 2024-06-26\nStart Time: 1045\nAbout: Come hear from the founders of Nixtla and how they partner with Microsoft in growing their business!",
  "Session: Coding with an AI Assistant at your side\nPresenters: Nathan Peck, Senior Developer Advocate, AWS\nDate: 2024-06-27\nStart Time: 1500\nAbout: Generative AI is changing how work gets done. In this session we'll talk about coding assistants, and how they fit into the software development lifecycle. Coding assistants can teach new concepts, accelerate developer research tasks, improve existing code, automate boilerplate code creationg, and even help develop complex brand new features from scratch",
  "Session: Tame your LLMs with Rust\nPresenters: Darko Mesaros, Principal Developer Advocate, AWS\nDate: 2024-06-26\nStart Time: 1045\nAbout: Building chat bots is fun! Building command line applications in Rust is even more fun! So join me in this session as we combine the two, and we look into the ways how you can create command line applications that use LLMs on Amazon Bedrock with Rust",
  "Session: 10 Tools & Tips to Upgrade Your Legacy Code with GenAI\nPresenters: Vinicius Senger , Senior Developer Advocate, AWS, Jonathan Vogel, Solutions Architect, AWS\nDate: 2024-06-27\nStart Time: 1055\nAbout: Programming languages like Java have been in the market for almost 30 years, resulting in hundreds of thousands of lines of legacy code that need maintenance and upgrades. In this talk, we'll explore how genAI can revolutionize the process of upgrading legacy code. You'll learn about 10 essential tools and tips to efficiently refactor, modernize, and enhance your existing Java codebase.",
  "Session: Insights from Snorkel AI running Azure AI Infrastructure\nPresenters: Lachlan Ainley, Senior PMM, Microsoft, Humza Iqbal, Senior Researcher, Snorkel AI\nDate: 2024-06-27\nStart Time: 1530\nAbout: Join us and hear from the Snorkel AI team about their experience and lessons learned using Azure AI infrastructure powered by NVIDIA GPUs. Learn about how Snorkel Researchers were able to run experiments quickly from small projects to large-scale distributed jobs on multiple GPUs reliably and with full monitoring mechanisms.",
  "Session: GitHub's AI-Powered Security Platform\nPresenters: Sarah Khalife, Principal Solutions Engineer, GitHub\nDate: 2024-06-27\nStart Time: 1330\nAbout: null",
  "Session: Accelerate your AI journey with Azure AI model catalog\nPresenters: Sharmila Chokalingam, Sr. Product Marketing Manager, Microsoft\nDate: 2024-06-26\nStart Time: 1324\nAbout: Learn how the Azure AI model catalog helps you discover and operationalize flagship LLMs and SLMs on Azure and unlocks access to a wide collection of models with enterprise data privacy, content safety compliance, and security built in. Experience live demos of deploying popular LLMs like Mistral, Phi3 & Llama3 and finally, take a deep dive into how the model catalog has enabled organizations to drive innovation, efficiency, and strategic decision-making with real-world examples.",
  "Session: The future of programming with GitHub Copilot\nPresenters: Christina Warren, Senior Developer Advocate, GitHub, Christopher Harrison,  Senior Developer Advocate, GitHub\nDate: 2024-06-27\nStart Time: 1300\nAbout: With the launch of generative AI and GitHub Copilot, there are both new skills for developers to learn and workflows to adopt. As this space continues to grow, we want to explore where the future will take us and how to best position ourselves to take advantage of new technologies. Let's discuss what workloads are best offloaded to Copilot, how to get the most out of the tool, and the new features coming to GitHub Copilot.",
  "Session: Recent Major Releases in GitHub Copilot\nPresenters: Yasir Al-Ibrahem, Principal Solutions Engineer, GitHub\nDate: 2024-06-27\nStart Time: 1230\nAbout: Join this session to learn more about how GitHub is incorporating GenAI across GitHub Advanced Security (GHAS) in addition to the core platform. Sarah Khalife, Principal Solutions Engineer, will provide an overview of key features including code scanning, secret scanning, and supply chain security, highlighting the latest AI-powered capabilities.",
  "Session:  Advanced RAG use-cases: Accessing your Database with Agents\nPresenters: Kurtis Van Gent, Staff Software Engineer , Google\nDate: 2024-06-26\nStart Time: 1245\nAbout: RAG & LLM Frameworks: This in-depth technical session delves into real-world use cases and design patterns for building generative AI applications on top of your databases. We’ll cover evolving beyond semantic search, and using agentic patterns to implement dynamic grounding using various RAG techniques, giving you valuable insights on implementing enterprise-grade gen AI solutions.\n",
  "Session:  Automate the boring stuff with Gemini on Google Cloud Vertex A\nPresenters: Holt Skinner, Developer Advocate, Google\nDate: 2024-06-27\nStart Time: 1245\nAbout: Multimodality: In this session, we'll do an in-depth exploration of how developers can use Gemini multimodal generative ai models to build custom applications and agents which can simplify and automate repetitive tasks. This session will dive into the latest advancements in Multimodal Generative AI, featuring Gemini 1.5 Flash and its capabilities to process and understand diverse data types including text, code, images, PDFs, audio, and video. Discover how to seamlessly integrate these multimodal models with external tools using Function Calling and Reasoning Engine, enabling the creation of sophisticated, end-to-end automated solutions. Whether you are looking to automate tasks or build innovative AI-driven applications, this session will equip you with the practical skills and knowledge to leverage the full potential of Google Cloud's cutting-edge AI technologies.",
  "Session: Building with Open Models on Vertex AI \nPresenters: Keelin McDonell, Product Manager, Vertex AI , Google\nDate: 2024-06-26\nStart Time: 1532\nAbout: Open Models: In this session, we'll explore how developers can use Google Cloud's Vertex AI platform to build safe, secure applications with open models. Using Google's Gemma model, we'll dive into an end-to-end example of model discovery, tuning, and deployment as part of real-world application.",
  "Session: Building security around ML\nPresenters: Dr. Andrew Davis, Chief Data Scientist, HiddenLayer\nDate: 2024-06-26\nStart Time: 1532\nAbout: The field of Adversarial ML has been active since at least 2013 and despite over a decade of attempts to make models more robust to imperceptible changes in the input, attack methods still outpace the ability to defend neural networks and other machine learning models. In this talk, we'll get into why adversarial examples are becoming increasingly relevant with the advent of agentic multimodal LLMs and what we can do to defend these models.",
  "Session: Context is the king - the evolution of a modern AI coding assistant\nPresenters: YK Sugi, AI Developer Advocate, Sourcegraph, Sourcegraph\nDate: 2024-06-26\nStart Time: 1510\nAbout: CodeGen & Dev Tools: \"If you’ve ever tried any AI coding assistant tool, you may have noticed: they kind of suck. ChatGPT doesn’t know anything about your codebase, and even tools that are supposed to be able to answer questions about it often fail.\n\nStarting from simply being able to talk about a single file, to being able to include specific files, then incorporating code search, coding assistants have evolved a lot over the past year or so.\n\nHowever, most coding assistants are still not able to incorporate the full context of your codebase as well as things like Linear issues, design docs on Notion, and more.\n\nIn this talk, I’ll take you on a journey of how we fixed this problem by leveraging new and interesting strategies to incorporate just the right context without blowing up your context window.\"",
  "Session: Acceleration is all you need (now): how we boosted inference performance by 10x on OctoStack \nPresenters: Jason Knight, Co-Founder and VP of ML, OctoAI\nDate: 2024-06-27\nStart Time: 1322\nAbout: GPU & Inference: Haven't you heard? GPUs are the new gold. If you're strapped for compute you're not alone. And if you already have some H100s on hand, you're probably looking for ways to get more bang for your buck. Enter OctoStack, the new Generative AI inference stack that you can deploy to any environment. In this talk, we'll tell you exactly how we got OctoStack to outperform DIY deployments, including VLLM, by 10X for high-concurrency use cases. We've spent a decade optimizing the heck out of the whole stack, and now we're ready spill all our secrets. If speculative decoding, custom kernels and CUDA graphs pique your interest, you're our kind of nerd. Come check it out! ",
  "Session: Mitigating LLM Hallucination Risk Through Research Backed Metrics\nPresenters: Yash Sheth, Co-founder & COO, Galileo\nDate: 2024-06-27\nStart Time: 1040\nAbout: Evals & LLM Ops: \"In the context of LLMs, “hallucination” refers to a phenomenon where the model generates incorrect, nonsensical, or unreal text. Identifying and mitigating hallucinations is critical for trustworthy LLM application deployment at scale. In this talk, we will showcase ChainPoll – a unique and powerful methodology to evaluate the quality of LLM outputs, focusing on RAG and fine-tuning use cases. ChainPoll-based metrics have showcased a roughly 85% correlation with human feedback while being low-cost and low-latency to compute. \n\nExpected takeaways:\n\n- Deep dive into research-backed metrics to evaluate the quality of the inputs (data quality, RAG context quality, etc.) and outputs (hallucinations) while building LLM-powered applications\n- Evaluation and experimentation framework while prompt engineering with RAG and fine-tuning with your own data\n- A demo-led practical guide to building guardrails and mitigating hallucinations\"",
  "Session: Different levels of scale in LLMOps pipeline\nPresenters: Aurimas Griciūnas, CPO, Neptune\nDate: 2024-06-26\nStart Time: 1530\nAbout: RAG & LLM Frameworks: \"The term LLMOps has been around for just under 2 years. In the meantime, we have gone from using fine-tuned foundation models to running complex Agentic AI systems in production. Many breakthroughs are yet to be made and hardware limitations to be overcome.\n\nIn this talk I will walk you through the entire LLMOps pipeline as if we were building an AI system from scratch. From building foundation models and fine-tuning them to observing complex Agentic AI systems in production. I will emphasize the different levels of scalability requirements for infrastructure and tooling at each step.\"",
  "Session: ColBERT at scale with RAGStack\nPresenters: Phil Nash, Developer Relations Engineer, Datastax, Datastax\nDate: 2024-06-26\nStart Time: 1312\nAbout: RAG & LLM Frameworks: \"RAG with vector databases has become a standard in GenAI applications, but the simple approach doesn't always produce the most relevant results. Contextualized Late Interaction over BERT (ColBERT) can overcome the shortcomings of traditional RAG, but how do you implement ColBERT at scale?\n\nThis talk introduces ColBERT, how it improves upon simple vector search, and how you can use it with the open-source RAGStack. Through live demos, you'll see how you can implement ColBERT embeddings, index them in Astra DB and build better retrieval for your GenAI application.\"",
  "Session: Tool Calling with Open Source LLMs\nPresenters: Rick Lamers, AI Researcher/Engineer, Groq\nDate: 2024-06-26\nStart Time: 1245\nAbout: Evals & LLM Ops: We all want faster, cheaper and more accurate tool calling abilities, but what are our options for improving accuracy and reliability of tool calling with Open Source LLMs? A systematic approach suggests a robust evaluation system is required to properly understand how every tiny design decision influences total system performance. When working with open source LLMs like Llama 3, the need to rigorously evaluate is crucial as many more adjustments can be made that influence the Tool Calling process.\n\nDuring this talk you will learn what a baseline evaluation looks like and how a tradeoff surface emerges as you decide on implementation details like fine tuning, prompt/encoding choices, streaming, retries, and more.",
  "Session: Train LLMs and Foundation-Scale Models Faster with Purpose-Built and Performance Optimized Cloud Infrastructure\nPresenters: Paul Sebexen, Cloud Engineering - Primitives, Lambda Labs\nDate: 2024-06-27\nStart Time: 1307\nAbout: GenAI models get larger every day and the infrastructure required to train them only gets more complex and harder to access. Navigating a sea of cloud providers or trying to rapidly scale up on-prem compute can be difficult at best -- just when you find the perfect solution at a fair price, you learn the lead time is too long or the hardware is not as reliable as advertised. If only there was a way to access exactly the amount of training compute power you need precisely when you need it.\nWe are excited to introduce 1-Click Clusters, a new way to perform distributed training at scale. 1CC is a flexible way to access GPU clusters of all sizes for weeks or months at a time. Whether your project needs a quick burst of extra power or might scale up and down over time, you can reserve compute as simply as booking a hotel room. We will discuss features and how things work beneath the software to help you learn what to look out for and how to maximize your training efficiency.",
  "Session: Open-source function calling models with Fireworks AI\nPresenters: Ray Thai, Founding Product Manager, Fireworks\nDate: 2024-06-27\nStart Time: 1045\nAbout: The next frontier of LLMs is creating agents to take action and connect to external knowledge sources. However, it can be difficult ensuring that models respond reliably, intelligently and quickly. Fireworks founding PM Ray Thai walks through the benefits of open-source function calling models and provides a tutorial on Fireworks’ new, Llama 3-based Firefunction-v2 model. Firefunction-v2 offers fast, reliable function-calling for real-world assistant use cases by enhancing Llama 3’s function calling ability while preserving its chat and instruction-following capabilities.",
  "Session: The future of RAG is agentic\nPresenters: Tirumarai Selvan, Principal Product Manager, Hasura\nDate: 2024-06-26\nStart Time: 1045\nAbout: RAG is the goto approach for AI to interact with data that it is not trained on. But beyond simple PoCs, writing your own RAG pipeline can be frustratingly complex. Why? Because fundamentally users can ask all kinds of questions that you as a developer may not have prepared for. So what we really need is AI doing RAG for us. Enter agentic RAG.\n\nIn this talk, we make a case for why agentic RAG is the future of RAG apps. Instead of spending time setting up complex RAG pipelines, developers should be spending time preparing quality data and letting the RAG agents do the heavy lifting of query planning, data retrieval and LLM orchestration. Developers should also be able to observe the RAG agent and be able to make it perform better continuously. We will show a quick demo of Pacha, the world’s first RAG agent that works with private data.",
  "Session: Building Smarter AI Applications with GraphRAG\nPresenters: Zach Blumenfeld, AI/ML Product Specialist, Neo4j\nDate: 2024-06-26\nStart Time: 1510\nAbout: RAG & LLM Frameworks: Learn about the power of GraphRAG (Graph Retrieval Augmented Generation) to improve the accuracy, relevance, and quality of LLM responses. While LLMs offer great potential, they can face challenges with lack of domain knowledge and hallucination. GraphRAG helps overcome these challenges by integrating vector search with knowledge graphs and data science techniques to improve context, semantic understanding, and personalization while facilitating real-time updates. In this session, we will cover GraphRAG through a real-world practical example, from creating a starter knowledge graph with a vector index to identifying and implementing useful GraphRAG patterns in a GenAI application.",
  "Session: Field Guide to Knowledge Graphs\nPresenters: Andreas Kolleger, Knowledge Engineer, Neo4j\nDate: 2024-06-27\nStart Time: 1510\nAbout: RAG & LLM Frameworks: This talk will share up-to-date learnings from the evolving field of knowledge graphs: from live case study examples at many of the world’s largest organizations, to the latest technologies & integration patterns, to how to think about knowledge graphs more generally and where they add value. You will come away with an understanding of how knowledge graphs can play the critical role of left brain to complement the statistically-derived LLM + Vector right brain. You will hear how these two techniques can work together to create more reliable and powerful solutions, in an enterprise landscape where many GenAI use cases call for the use of both hemispheres.",
  "Session: GitHub Copilot - The World’s Most Widely Adopted AI Developer Tool\nPresenters: Dave Burnison, Senior Developer Advocate    , GitHub\nDate: 2024-06-27\nStart Time: 1040\nAbout: GitHub Copilot was introduced as “Your AI pair programmer” in January of 2021. Since then, we have been adding more and more capabilities to increase developer productivity and happiness. We’ve gone from simply leveraging AI to generate code to explaining existing code, generating unit tests, propose fixes for bugs, making code robust / secure, summarizing pull requests, having conversations tailored to your organization’s repositories, providing answers to your questions based on your organization’s knowledge base and so much more! Let's explore how to get started with GitHub Copilot, its ever growing list of capabilities, and how to make the most out of the tool.",
  "Session: What We Learned From A Year of Building With LLMs\nPresenters: Eugene Yan, Senior Applied Scientist, Amazon, Hamel Husain, AI Engineer, Parlance Labs, Jason Liu, Consultant (Instructor), Independent, Dr Bryan Bischof, Head of AI , Hex, Charles Frye, AI Engineer, Modal Labs, Shreya Shankar, UCB EECS & EPIC Lab, UC Berkeley\nDate: 2024-06-27\nStart Time: 1603\nAbout: Special double-feature closing keynote from the 6 authors of the hit O'Reilly article on Applied LLMs.",
  "Session: Unlocking Developer Productivity across CPU and GPU with MAX\nPresenters: Chris Lattner, CEO, Modular\nDate: 2024-06-27\nStart Time: 904\nAbout: Today's leading generative AI applications have workloads that span high performance GPU compute, CPU preprocessing, data-loading, and orchestration — often spread across a combination of Python, C++/Rust, and CUDA C++ — which increases the complexity and slows down the cycle of innovation. This talk explores the capabilities and power of the Modular Mojo programming language and Modular Accelerated Xecution (MAX) platform, which unifies CPU and GPU programming into a single Pythonic programming model that is simple and extensible. This results in reduced complexity and improved developer productivity, and streamlines innovation. We'll walk through CPU and GPU support with real-world examples, providing details of how AI application developers can use MAX and Mojo to define an end-to-end AI pipeline and overcome the complexities. ",
  "Session: Spreadsheets-are-all-you-need: Decoding the Decoder LLM without de code\nPresenters: Ishan Anand, VP Product (Spreadsheets Are All You Need), Edgio\nDate: 2024-06-26\nStart Time: 1634\nAbout: The struggle to grasp the inner workings of AI models can leave even experienced engineers from non-ML backgrounds feeling lost in a sea of terminology and new concepts. What if the key to understanding the intricate mechanics of LLMs didn't require a Ph.D.? This session offers an innovative approach, employing spreadsheets to dissect and demystify the architecture of decoder-based LLMs using a fully working implementation of GPT-2 entirely in Excel. Attendees will tour through GPT-2's architecture from tokenization, embeddings, attention, multi-layer perceptron, all translated into the accessible format of spreadsheets with minimal abstractions to get in the way. By the end, you'll gain unparalleled insights into AI's backbone, transforming abstract concepts into tangible, understandable processes, without ever touching code.",
  "Session: Hasura Launch: Have APIs failed RAG use-cases?\nPresenters: Tanmai Gopal, CEO, Hasura\nDate: 2024-06-26\nStart Time: 1007\nAbout: \"Over the last 3 months, summarize the top billing issues faced by my enterprise customers within the first 30 days of their onboarding.\"\"\n\nOn the surface, building an internal AI customer intelligence application that can answer questions like this is a perfect use-case for Gen AI.\nHowever, building a production ready app that retrieves the data (RAG) before hauling it off to your favorite LLM for summarization soon becomes a terrible engineering experience. \n\nThe data is spread across 3 places: a tickets database (eg: elastic), a CRM (eg: salesforce) and your user-accounts transactional database (eg: postgres).\nIn production, your app can't access the data from these databases directly. Given security & privacy concerns, your app won't have direct access to these databases.\nMaking independent retrieval requests to each of these sources and then joining them in memory might be prohibitively expensive and needs a level of query planning to do efficiently.\nMoving all data into one location is expensive to build, maintain and govern \nPredictable quality is further made hard because underlying data formats and storage interfaces are continuously changing.\nDifferent types of user queries might require additional filtering and joining of data, which becomes hard to generalize.\n\nAPIs solve almost all of these very well known challenges. APIs offer standardization and security. APIs can provide a stable contract to interact with underlying data.\nAnd in all likelihood, you already have APIs on these internal and external data sources. \n\nIronically, while APIs have become a necessity for other parts of the stack, they are clearly not the first thing that AI engineers building RAG reach for. \n\nIn this talk, we'll discuss:\nWhy API based retrieval doesn't work well for RAG\nWhat we need from our existing internal and external APIs to make them RAG ready\nHow we can get existing APIs to become RAG ready without needing to rebuild the APIs\n\nBased on our work at Hasura with early-stage AI startups and Fortune 100 customers alike, I'll share key learnings on how we can set the stage to experiment and productionize RAG.\n\nThis talk will be technical, with code demos (possibly with some live coding!) and end with key resources (reference architectures, API best practices, tools/technologies) that attendees can take back to their work.\"",
  "Session: Building reliable applications with structured outputs\nPresenters: Michelle Pokrass, Engineering Lead, OpenAI, Atty Eleti, Member of Technical Staff, OpenAI\nDate: 2024-06-26\nStart Time: 921\nAbout: AI is inherently fuzzy – it is divergent, expressive, creative, and otherwise hard to tame. In contrast, your engineering systems are rigid, typed, and depend on consistent structures and values. The perennial challenge in AI engineering has been marrying these two paradigms to build both reliable and transformative applications. In this talk we'll explore strategies and tools for bridging this gap and getting the most out of your AI integration. ",
  "Session: Llamafile: bringing AI to the masses with fast CPU inference\nPresenters: Stephen Hood, Open Source AI Lead, Mozilla, Justine Tunney, OSS Lead, Mozilla\nDate: 2024-06-26\nStart Time: 941\nAbout: null",
  "Session: Hypermode Launch\nPresenters: Kevin Van Gundy , CEO, Hypermode\nDate: 2024-06-26\nStart Time: 1013\nAbout: null",
  "Session: Pydantic is STILL all you need\nPresenters: Jason Liu, Consultant (Instructor), Independent\nDate: 2024-06-26\nStart Time: 1615\nAbout: PLEASE ONLY RETURN JSON\n\nIt's been a year after Jason's most popular talk at the AI Engineering Summit. I wanted to come back with all the learnings I've had in the past year. How I've learned that Pydantic is still all you need, and bring more applications and use cases that I've seen in businesses and my thoughts on where the space will be heading in the future.",
  "Session: LangChain Launch: Infrastructure for building reliable agents\nPresenters: Harrison Chase, CEO, LangChain\nDate: 2024-06-27\nStart Time: 1020\nAbout: A main issue with agents is that they are not reliable enough. It's easy to build a prototype of agents, but it's still a lot of engineering work to get them to perform reliably. Infrastructure (and tooling) can help make this easier - but thinking about and understanding your application's \"cognitive architecture\" will always be necessary. This talk will discuss new infrastructure (and tooling) that still gives you full control of the \"cognitive architecture\" of your application.",
  "Session:  From Software Developer to AI Engineer: Practical Strategies to Innovate with Generative AI\nPresenters: Antje Barth, Principal Developer Advocate, AWS\nDate: 2024-06-27\nStart Time: 923\nAbout: In this keynote, Antje explores how generative AI is transforming the landscape of software development, enabling developers to innovate like never before. She will showcase the latest advancements in AI and demonstrate the powerful capabilities of generative AI tools available on AWS. You will learn how to harness these tools to accelerate your development processes, enhance creativity, and build robust, AI-driven applications.",
  "Session: Copilots Everywhere\nPresenters: Thomas Dohmke, CEO, GitHub, swyx, Editor, Latent.Space\nDate: 2024-06-27\nStart Time: 1640\nAbout: null",
  "Session: BotDojo Launch: Enhancing AI Assistants with Evaluations and Synthetic Data\nPresenters: Paul Henry, CEO, BotDojo\nDate: 2024-06-26\nStart Time: 1603\nAbout: So you've built an AI assistant, but how do you gain the confidence to deploy it to production? In this live demo we introduce BotDojo, a platform that helps you build and improve LLM applications. We'll demonstrate how it identifies gaps in your assistant's knowledge through targeted evaluations. Then, we'll show how to generate synthetic data from existing documentation and support interactions to improve performance.\n",
  "Session: Useful General Intelligence\nPresenters: Danielle Perszyk, Cognitive Scientist, Adept\nDate: 2024-06-27\nStart Time: 1001\nAbout: AGI is the north star for all the central players in AI, but it’s unclear what AGI is and how it could be useful. What would it take to build a general intelligence that’s truly useful to humanity—a general-purpose toolkit that levels up the intelligence of both humans and computers while keeping us in the driver’s seat? We propose Useful General Intelligence (UGI): a common language for humans and computers. UGI is both a meta-tool for doing computer work and a meta-interface for the computer, and it involves agents that not only execute explicitly stated goals but also infer them implicitly. In this talk, we show how we’re developing the building blocks for UGI with a range of enterprise customers. ",
  "Session: What's new from Anthropic and what's next\nPresenters: Alex Albert, Head of Developer Relations, Anthropic\nDate: 2024-06-27\nStart Time: 942\nAbout: Explore Anthropic's latest strides in large language models, emphasizing enhanced reasoning and multimodal capabilities. We'll showcase how these advancements translate into powerful developer tools, APIs, and best practices for building sophisticated, RSP-aligned AI applications.",
  "Session: The Future of Knowledge Assistants\nPresenters: Jerry Liu, CEO, LlamaIndex\nDate: 2024-06-26\nStart Time: 1653\nAbout: null",
  "Session: Convex Launch\nPresenters: Jamie Turner, CEO, Convex\nDate: 2024-06-26\nStart Time: 1001\nAbout: null",
  "Session: Welcome & Introduction\nPresenters: Benjamin Dunphy, Co-founder, Software 3.0, LLC\nDate: 2024-06-26\nStart Time: 900\nAbout: Benjamin Dunphy, co-founder of the AI Engineer World's Fair and managing partner at Software 3.0, LLC, welcomes attendees and makes a few key announcements. ",
  "Session: Welcome & Introduction\nPresenters: Benjamin Dunphy, Co-founder, Software 3.0, LLC\nDate: 2024-06-27\nStart Time: 900\nAbout: Benjamin Dunphy, co-founder of the AI Engineer World's Fair and managing partner at Software 3.0, LLC, welcomes attendees to day 2 and makes a few key announcements. ",
  "Session: Opening Keynote: The Rise of the Planet of the AI Engineer\nPresenters: swyx, Editor, Latent.Space\nDate: 2024-06-26\nStart Time: 910\nAbout: One year into the Rise of the AI Engineer, what are the top 10 most important questions that we are here to work on next?",
  "Session: Hyperspace Launch\nPresenters: Varun Mathur, CEO, Hyperspace\nDate: 2024-06-26\nStart Time: 1019\nAbout: null",
  "Session: AI Agents and the future enterprise\nPresenters: Satya Nitta, Co-founder and CEO, Emergence AI\nDate: 2024-06-26\nStart Time: 1609\nAbout: AI agents are poised to revolutionize software systems and devices, promising unprecedented automation and efficiency for enterprises. However, the road to this future is riddled with challenges such as inefficiency, non-determinism, high costs, discoverability, and rapid technological evolution. At Emergence, we are tackling these challenges head-on to transform the vision of useful AI agents into reality. Join us as we unveil our Orchestrator, which is a meta-agent designed to intelligently route tasks, integrate diverse AI agents, and future-proof enterprise systems. We will also show work from our R&D labs where we are advancing the science of agents and developing a web agent in the open source to automate complex enterprise workflows. Discover how our experience in building scalable AI solutions and our commitment to open-source development are paving the way for a seamlessly automated world.\"",
  "Session: Optimizing LLMs in Insurance with DSPy: Beyond Manual Tuning\nPresenters: Jeronim Morina, Senior MLOps Engineer, AXA\nDate: 2024-06-26\nStart Time: 1155\nAbout: \"In the insurance industry, LLMs promise efficiency but often get bogged down by manual tuning for optimal performance. DSPy changes the game.\n\nTraditional LLM deployment is a high-effort, error-prone process, demanding extensive prompt engineering and fine-tuning across multiple steps.\n\nImagine deploying LLMs where manual optimizations are replaced by DSPy's automated, efficient prompt and weight optimization, streamlining processes and slashing costs.\n\nWe'll cover how DSPy revolutionizes LLM deployment in insurance, from enhancing customer interactions to efficient claims management. Attendees will see DSPy's direct impact on operational efficiency, cost-effectiveness, and model reliability through practical applications at AXA and beyond.\"",
  "Session: Iterating on LLM apps at scale: Learnings from Discord\nPresenters: Ian Webster, Senior Staff Software Engineer, Discord\nDate: 2024-06-26\nStart Time: 1115\nAbout: \"Discover best practices for rapid evaluation and iteration on LLM apps in large-scale applications, with a first-hand account from Discord's engineering team.  This talk covers development workflow and evaluation methodology in order to measure model & prompt improvements, mitigate risks, and speed up development.  We'll discuss the best practices that we refined and implemented internally, the tooling and automation that got us shipping improvements consistently, and some of the strange and wonderful things that happen with LLMs in the wild!\"",
  "Session: AI Frontiers in Trust and Safety: Combatting Multifaceted Harm on Tinder at Scale\nPresenters: Vibhor Kumar, AI Engineer, Tinder\nDate: 2024-06-26\nStart Time: 1135\nAbout: Harassment, Hate Speech, Pig Butchering Scams, and Underage users. These are just some of the possible categories of the (very) long tail of harm on Tinder. How can we possibly train, serve, and maintain models for all of these, at global, real-time scale? We build off of pre-trained models and an increasingly mature open-source ecosystem. In this talk, we'll cover how we've dramatically accelerated our modeling pipeline with (1) human-AI hybrid dataset generation for different harm vectors, (2) automated parameter-efficient fine-tuning of open-source large language and multimodal models for violation detection, and (3) serving fine-tuned adapters efficiently in real-time and at scale using LoRAX and cascade classification.",
  "Session: A Practical Guide to Efficient AI\nPresenters: Shelby Heinecke, Senior AI Research Manager, Salesforce\nDate: 2024-06-26\nStart Time: 1400\nAbout: In the past years, we’ve witnessed a whirlwind of AI breakthroughs powered by extremely large and resource-demanding models. And now, faced with actually deploying these models at scale, AI engineers and builders are left to pick up the pieces on how to improve latency and resource consumption practically. In parallel, the on-device AI movement is heating up, imposing even more physical constraints on AI model deployment. In this talk, we will first identify key sources of inefficiency in AI models. Then, we will discuss techniques and practical tools to improve efficiency, from model architecture selection, to quantization, to prompt optimization.",
  "Session: Navigating Challenges and Technical Debt in LLMs Deployment \nPresenters: Ahmed Menshawy, Vice President of AI Engineering, Mastercard\nDate: 2024-06-26\nStart Time: 1440\nAbout: \"Large Language Models (LLMs) have become essential in advancing AI, enabling remarkable capabilities in natural language processing and understanding. However, the efficient deployment of LLMs in production environments reveals a landscape of challenges and technical debt.\n\nEthically, LLMs face issues such as bias amplification, where they might perpetuate existing stereotypes in their outputs. Misinformation is another concern, with the potential misuse of LLMs to create convincing yet false narratives. Privacy risks emerge from LLMs possibly memorizing and revealing personal data. Moreover, societal challenges include the impact on employment, as LLMs could automate tasks but also lead to job displacement. These challenges highlight the need for careful management and ethical considerations in the deployment of LLMs.\n\nIn this talk, Ahmed will highlight the key challenges and technical debt associated with LLMs' deployment, which demands customization and sophisticated engineering solutions not readily available in broad-use machine learning libraries or inference engines.\"",
  "Session: Breaking AI’s 1 Gigahertz Barrier\nPresenters: Sunny Madra, GM of GroqCloud, Groq\nDate: 2024-06-27\nStart Time: 1142\nAbout: It’s been 25 years since Intel broke the 1 Ghz speed barrier for a general purpose microprocessor. What does 1 Ghz AI inference mean? What application capabilities will this enable? How will we achieve it? Groq’s mission is to build the AI computer that will power the next generation of software.",
  "Session: Making Open Models 10x faster and better for Modern Application Innovation\nPresenters: Lin Qiao, CEO, Fireworks\nDate: 2024-06-27\nStart Time: 1420\nAbout: Generative AI powers the next generation of real time applications. The key to success of modern application development in the Gen AI era is secure, latency-sensitive and low cost LLM serving solution,  which Firework’s  enterprise grade deployment provides. Fireworks AI accelerates innovation through its SaaS platform of low latency inference and high quality fine-tuning of 100+ models, across the state of the art LLMs, image/video/audio generation, embedding and multimodality models. These advantages are delivered through Fireworks' proprietary FireAttention technology, 4x-15x faster than the OSS alternatives. To bring the totality of knowledge together, Fireworks tuned their own FireFunction model to integrate hundreds of models and API calling together. Fireworks' adoption is the fastest in the industry and it also enables a software stack capable of extracting the most across different hardware and deployment options.",
  "Session: Compute & System Design for Next Generation Frontier Models\nPresenters: Dylan Patel, Chief Analyst, SemiAnalysis\nDate: 2024-06-27\nStart Time: 1122\nAbout: Presentation will go over current and future hardware requirements for next generation frontier models",
  "Session: LLM Quality Optimization Bootcamp\nPresenters: Thierry Moreau, Co-Founder, OctoAI, Pedro Torruella, Staff DevRel Engineer, OctoAI\nDate: 2024-06-26\nStart Time: 1230\nAbout: Want to unlock the full potential of your LLM applications? In this session you'll learn essential LLM quality optimization techniques for custom behavior, reliability and accuracy. We'll pack a ton into the hour, including:\n\nLevel 1: Learn prompt engineering to master LLMs for summarization and format responses in structured JSON for seamless downstream use.\nLevel 2: Discover how retrieval augmented generation tackles hallucinations in real-world LLM applications.\nLevel 3: Explore fine-tuning techniques to close quality gaps, especially in classification, and unlock cost savings by replacing pricey proprietary models with affordable open-source LLMs.",
  "Session: Covalent Launch: The GPU Cheatcode: Fine-tune 20 Llama Models in 5 Minutes\nPresenters: Santosh Radha, Head of Product/Research, Agnostiq (Covalent)\nDate: 2024-06-27\nStart Time: 1115\nAbout: The complexity and scarcity of deploying GPUs can bring AI development to a standstill. What if there was a better way to train, fine-tune, and serve models on accelerated compute infrastructure entirely in Python? See how during this session where we fine-tune 20 Llama models without doing any infrastructure work. Startups and enterprises can finally gain unprecedented speed and agility to build, iterate, and deploy anything that they can imagine, from multi-agent, multi-modal AI applications, to digital twins for real world simulation. What used to take weeks with dozens of best-in-class engineers can now be accomplished in hours from a single notebook.",
  "Session: Scott Wu and the Story of Devin\nPresenters: Scott Wu, CEO, Cognition\nDate: 2024-06-27\nStart Time: 1440\nAbout: null",
  "Session: Accelerating Mixture of Experts Training With Rail-Optimized InfiniBand Networking in Crusoe Cloud\nPresenters: Ethan Petersen , Senior Developer Advocate, Crusoe\nDate: 2024-06-27\nStart Time: 1202\nAbout: State-of-the-art machine learning models are increasingly using techniques like mixture of experts that enable larger-scale models to be trained more efficiently by distributing layers of the model across multiple neural networks. This sparse distribution of model state puts increasing pressure on cluster-level networking while training. At Crusoe Cloud, we’ve built a high-performance InfiniBand network that's designed to provide the highest possible performance for these state-of-the-art training techniques. We use a “rail-optimized” design, reducing the number of hops between any set of GPUs in our cluster, accelerating all2all performance, and reducing training time. Learn more about how to utilize Crusoe Cloud rail-optimized networks to accelerate your training workloads.",
  "Session: It’s Not Just Vectors: Augment LLM Capabilities with MongoDB Aggregation Framework\nPresenters: Fabian Valle, Sr. Engineer, MongoDB\nDate: 2024-06-25\nStart Time: 1700\nAbout: This talk explores how MongoDB's Aggregation Framework transcends limitations of \"classic RAG\". While RAG utilizes vector representations and semantic relevance for data retrieval, it often relies on pre-defined knowledge bases, limiting the scope of analysis. The Aggregation Framework, on the other hand, empowers you to analyze entire collections directly within MongoDB. Furthermore, the Aggregation Framework offers unparalleled flexibility for complex calculations and data transformation."
]